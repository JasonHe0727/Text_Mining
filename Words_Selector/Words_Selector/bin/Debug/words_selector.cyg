import 'io'
import 'MySQL'
def getLines(file) { # retrieve every non-empty line from the given file
	r = reader(file,'utf-8')
	lines = []
	while r.peek() != -1 {
		line = r.readLine()
		if line.trim() != string.empty {
			lines.append(line)
		}
	}
	return lines
}

def findWords(sentence, words){ # find the words in the sentence, return a boolean vector 
	a = []
	for i = 0,len(words) {
		result = sentence.find(words[i])
		if result >= 0 {
			a.append(true)
		} else {
			a.append(false) 
		}
	}
	return a
}

def cutSentence(filePath,stopPath){ # cut the sentence, using jieba.Net (which is awesome!)
	print("Start cutting sentences.")
	stopwords = File.readAllText(stopPath,'utf-8')
	f = File.open(filePath,FileMode.Open)
	fileReader = reader(f,'utf-8')
	fileReader.readLine() # Skip the header
	seg_words = hashtable()
	sep = ['\t']
	while fileReader.peek()!=-1{
		line = fileReader.readLine().split(sep)
		if len(line) != 2 {
			print("error format line")
			continue
		}
		else {
			words = jieba_cut(line[1]) 
			foreach word in words{
				if stopwords.find(word)<0{
					seg_words[word] = true
				}
			}
		}
	}
	fileReader.close()
	dispose(f)
	print("Finish cutting sentences.")
	return seg_words
}

def writeSegWords(seg_words, outputPath){ # write the segments to a file
	words = seg_words.keys()
	f = File.open(outputPath,FileMode.Create)
	w = writer(f,'utf-8')
	foreach i in words {
		w.writeLine(i)
	}
	w.close()
	print("Segmented words has been written to file.")
	return words
}

def chi2(word_col, word_vecs, sentiment) { # Compute the Chi2 value in order to find the important words
	A = B = C = D = 0
	for i = 0,len(word_vecs) {
		a = word_vecs[i][word_col]
		sen = sentiment[i]  # true: postive false: negative
		if a {
			if sen {
				B = B + 1
			} else {
				A = A + 1
			}
		} else {
			if sen {
				D = D + 1
			} else {
				C = C + 1
			}
		}
	}
	N = A+B+C+D
	chi2_value =N*(A*D-B*C)^2 / ((A+C)*(A+B)*(B+D)*(C+D)) 
	return chi2_value
}

def loadDataFromCsvFile(filePath,words){
	# load data from csv file
	# file format:(delimited by tab)
	# sentiment	sentences 
	# positive	balabalabala...
	# negative	balabalabala...
	
	word_vecs = []
	sentiment = []

	file = File.open(filePath, FileMode.Open)
	fileReader = reader(file,'utf-8')
	trainData = []
	fileReader.readLine() # skip the header
	index = 1
	print("start finding words.")
	sep = ['\t']
	while fileReader.peek() != -1 {
		line = fileReader.readLine()
		t = line.split(sep)
		t[0] = string.lower(t[0])
		if t[0] == 'positive' or t[0] == 'netural' {
			word_vecs.append(findWords(t[1], words))
			sentiment.append(true)
		} 
		elif t[0] == 'negative' {
			word_vecs.append(findWords(t[1], words))
			sentiment.append(false)
		}
		else {
			printf('Unrecoginizable sentiment: {0}, drop it',t[0])
		}
		print(index)
		index = index + 1
	}
	fileReader.close()
	dispose(file)
	print("finish finding words.")
	print("start computing Chi2 values")
	chi2_values = []
	for word_col = 0,len(words) {
		chi2_values.append(chi2(word_col, word_vecs, sentiment))
	}
	print("finish computing Chi2 values")
	return chi2_values
}

def getSelectedWords(sorted_chi2_values,words,outputPath,k){
	f = File.open(outputPath,FileMode.Create)
	w = writer(f,'utf-8')
	count = 0
	for i = 0,len(sorted_chi2_values) {
		if count >= k {
			break
		}
		value = sorted_chi2_values[i]
		index = value[0]
		w.writeLine(words[index])
		count = count + 1
	}
	w.close()
	dispose(f)
}

def __MAIN__(args){
	trainPath = args[0] # train data file path
	stopPath = args[1] # stop words file path
	wordsPath = args[2] # output segmented words file path
	selectedWordsPath = args[3] # selected words file path
	k = args[4] # select top-k words
	seg_words = cutSentence(trainPath, stopPath)

	words = writeSegWords(seg_words,wordsPath)

	chi2_values = loadDataFromCsvFile(trainPath, words)
	chi2_list = sort_chi2_list(chi2_values)
	getSelectedWords(chi2_list, words,selectedWordsPath,k)
	print("Finished!")
}
